{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import pickle\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 3\n",
    "n_disc = 16\n",
    "n_gen = 64\n",
    "n_encode = 64\n",
    "n_l = 10\n",
    "n_z = 50\n",
    "img_size = 128\n",
    "batchSize = 20\n",
    "use_cuda = torch.cuda.is_available()\n",
    "n_age = int(n_z/n_l)\n",
    "n_gender = int(n_z/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_dir = \"./data/\"\n",
    "\n",
    "dataset = dset.ImageFolder(root=des_dir,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(img_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size= batchSize,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #input: 3*128*128\n",
    "            nn.Conv2d(n_channel,n_encode,5,2,2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(n_encode,2*n_encode,5,2,2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(2*n_encode,4*n_encode,5,2,2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(4*n_encode,8*n_encode,5,2,2),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        self.fc = nn.Linear(8*n_encode*8*8,50)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv = self.conv(x).view(-1,8*n_encode*8*8)\n",
    "        out = self.fc(conv)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(n_z+n_l*n_age+n_gender,\n",
    "                                          8*8*n_gen*16),\n",
    "                                nn.ReLU())\n",
    "        self.upconv= nn.Sequential(\n",
    "            nn.ConvTranspose2d(16*n_gen,8*n_gen,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(8*n_gen,4*n_gen,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(4*n_gen,2*n_gen,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(2*n_gen,n_gen,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(n_gen,n_channel,3,1,1),\n",
    "            nn.Tanh(),\n",
    "        \n",
    "        )\n",
    "        \n",
    "    def forward(self,z,age,gender):\n",
    "        l = age.repeat(1,n_age)\n",
    "        k = gender.view(-1,1).repeat(1,n_gender)\n",
    "        \n",
    "        x = torch.cat([z,l,k],dim=1)\n",
    "        fc = self.fc(x).view(-1,16*n_gen,8,8)\n",
    "        out = self.upconv(fc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dimg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dimg,self).__init__()\n",
    "        self.conv_img = nn.Sequential(\n",
    "            nn.Conv2d(n_channel,n_disc,4,2,1),\n",
    "        )\n",
    "        self.conv_l = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_l*n_age+n_gender, n_l*n_age+n_gender, 64, 1, 0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.total_conv = nn.Sequential(\n",
    "            nn.Conv2d(n_disc+n_l*n_age+n_gender,n_disc*2,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(n_disc*2,n_disc*4,4,2,1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(n_disc*4,n_disc*8,4,2,1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc_common = nn.Sequential(\n",
    "            nn.Linear(8*8*img_size,1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_head1 = nn.Sequential(\n",
    "            nn.Linear(1024,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc_head2 = nn.Sequential(\n",
    "            nn.Linear(1024,n_l),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self,img,age,gender):\n",
    "        l = age.repeat(1,n_age,1,1,)\n",
    "        k = gender.repeat(1,n_gender,1,1,)\n",
    "        conv_img = self.conv_img(img)\n",
    "        conv_l   = self.conv_l(torch.cat([l,k],dim=1))\n",
    "        catted   = torch.cat((conv_img,conv_l),dim=1)\n",
    "        total_conv = self.total_conv(catted).view(-1,8*8*img_size)\n",
    "        body = self.fc_common(total_conv)\n",
    "        \n",
    "        head1 = self.fc_head1(body)\n",
    "        head2 = self.fc_head2(body)\n",
    "        \n",
    "        return head1,head2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dz,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_z,n_disc*4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(n_disc*4,n_disc*2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(n_disc*2,n_disc),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(n_disc,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    netE = Encoder().cuda()\n",
    "    netD_img = Dimg().cuda()\n",
    "    netD_z  = Dz().cuda()\n",
    "    netG = Generator().cuda()\n",
    "else:\n",
    "    netE = Encoder()\n",
    "    netD_img = Dimg()\n",
    "    netD_z  = Dz()\n",
    "    netG = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find(\"Linear\") !=-1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netE.apply(weights_init)\n",
    "netD_img.apply(weights_init)\n",
    "netD_z.apply(weights_init)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerE = optim.Adam(netE.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "optimizerD_z = optim.Adam(netD_z.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "optimizerD_img = optim.Adam(netD_img.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labelTensor):\n",
    "    oneHot = - torch.ones(batchSize*n_l).view(batchSize,n_l)\n",
    "    for i,j in enumerate(labelTensor):\n",
    "        oneHot[i,j] = 1\n",
    "    if use_cuda:\n",
    "        return Variable(oneHot).cuda()\n",
    "    else:\n",
    "        return Variable(oneHot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    BCE = nn.BCELoss().cuda()\n",
    "    L1  = nn.L1Loss().cuda()\n",
    "    CE = nn.CrossEntropyLoss().cuda()\n",
    "    MSE = nn.MSELoss().cuda()\n",
    "else:\n",
    "    BCE = nn.BCELoss()\n",
    "    L1  = nn.L1Loss()\n",
    "    CE = nn.CrossEntropyLoss()\n",
    "    MSE = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_LOSS(imgTensor):\n",
    "    x = (imgTensor[:,:,1:,:]-imgTensor[:,:,:img_size-1,:])**2\n",
    "    y = (imgTensor[:,:,:,1:]-imgTensor[:,:,:,:img_size-1])**2 \n",
    "    out = (x.mean(dim=1)+y.mean(dim=1)).mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = pickle.load(open(\"fixed_noise.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_l = -torch.ones(80*10).view(80,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(fixed_l):\n",
    "    l[i//8] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_g = -1*torch.FloatTensor([1,-1,-1,-1,-1,1,1,1]).view(-1,1).repeat(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_l_v = Variable(fixed_l)\n",
    "fixed_img_v = Variable(fixed_noise)\n",
    "fixed_g_v = Variable(fixed_g)\n",
    "if use_cuda:\n",
    "    fixed_l_v = fixed_l_v.cuda()\n",
    "    fixed_img_v = fixed_img_v.cuda()\n",
    "    fixed_g_v = fixed_g_v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf='./result_tv_gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(30,niter):\n",
    "    for i,(img_data,img_label) in enumerate(dataloader):\n",
    "        \n",
    "        # make image variable and class variable\n",
    "        \n",
    "        img_data_v = Variable(img_data)\n",
    "        img_age = img_label/2\n",
    "        img_gender = img_label%2*2-1\n",
    "        \n",
    "        img_age_v = Variable(img_age).view(-1,1)\n",
    "        img_gender_v = Variable(img_gender.float())\n",
    "\n",
    "\n",
    "        if use_cuda:\n",
    "            img_data_v = img_data_v.cuda()\n",
    "            img_age_v = img_age_v.cuda()\n",
    "            img_gender_v = img_gender_v.cuda()            \n",
    "        \n",
    "        # make one hot encoding version of label\n",
    "        batchSize = img_data_v.size(0)\n",
    "        age_ohe = one_hot(img_age)\n",
    "        \n",
    "        # prior distribution z_star, real_label, fake_label\n",
    "        z_star = Variable(torch.FloatTensor(batchSize*n_z).uniform_(-1,1)).view(batchSize,n_z)\n",
    "        real_label = Variable(torch.ones(batchSize).fill_(1)).view(-1,1)\n",
    "        fake_label = Variable(torch.ones(batchSize).fill_(0)).view(-1,1)\n",
    "        \n",
    "        if use_cuda:\n",
    "            z_star, real_label, fake_label = z_star.cuda(),real_label.cuda(),fake_label.cuda()\n",
    "            \n",
    "            \n",
    "        ## train Encoder and Generator with reconstruction loss\n",
    "        netE.zero_grad()\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # EG_loss 1. L1 reconstruction loss\n",
    "        z = netE(img_data_v)\n",
    "        reconst = netG(z,age_ohe,img_gender_v)\n",
    "        EG_L1_loss = L1(reconst,img_data_v)\n",
    "            \n",
    "            \n",
    "        # EG_loss 2. GAN loss - image\n",
    "        z = netE(img_data_v)\n",
    "        reconst = netG(z,age_ohe,img_gender_v)\n",
    "        D_reconst,_ = netD_img(reconst,age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
    "        G_img_loss = BCE(D_reconst,real_label)\n",
    "\n",
    "        \n",
    "        \n",
    "        ## EG_loss 3. GAN loss - z \n",
    "        Dz_prior = netD_z(z_star)\n",
    "        Dz = netD_z(z)\n",
    "        Ez_loss = BCE(Dz,real_label)\n",
    "        \n",
    "        ## EG_loss 4. TV loss - G\n",
    "        reconst = netG(z.detach(),age_ohe,img_gender_v)\n",
    "        G_tv_loss = TV_LOSS(reconst)\n",
    "        \n",
    "        EG_loss = EG_L1_loss + 0.0001*G_img_loss + 0.01*Ez_loss + G_tv_loss\n",
    "        EG_loss.backward()\n",
    "        \n",
    "        optimizerE.step()\n",
    "        optimizerG.step()\n",
    "        \n",
    "\n",
    "\n",
    "        ## train netD_z with prior distribution U(-1,1)\n",
    "        netD_z.zero_grad()        \n",
    "        Dz_prior = netD_z(z_star)\n",
    "        Dz = netD_z(z.detach())\n",
    "        \n",
    "        Dz_loss = BCE(Dz_prior,real_label)+BCE(Dz,fake_label)\n",
    "        Dz_loss.backward()\n",
    "        optimizerD_z.step()\n",
    "        \n",
    "\n",
    "\n",
    "        ## train D_img with real images\n",
    "        netD_img.zero_grad()\n",
    "        D_img,D_clf = netD_img(img_data_v,age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
    "        D_reconst,_ = netD_img(reconst.detach(),age_ohe.view(batchSize,n_l,1,1),img_gender_v.view(batchSize,1,1,1))\n",
    "\n",
    "        D_loss = BCE(D_img,real_label)+BCE(D_reconst,fake_label)\n",
    "        D_loss.backward()\n",
    "        optimizerD_img.step()\n",
    "        \n",
    "\n",
    "        \n",
    "    ## save fixed img for every 20 step        \n",
    "    fixed_z = netE(fixed_img_v)\n",
    "    fixed_fake = netG(fixed_z,fixed_l_v,fixed_g_v)\n",
    "    vutils.save_image(fixed_fake.data,\n",
    "                '%s/reconst_epoch%03d.png' % (outf,epoch+1),\n",
    "                normalize=True)\n",
    "    \n",
    "    ## checkpoint\n",
    "    if epoch%10==0:\n",
    "        torch.save(netE.state_dict(),\"%s/netE_%03d.pth\"%(outf,epoch+1))\n",
    "        torch.save(netG.state_dict(),\"%s/netG_%03d.pth\"%(outf,epoch+1))\n",
    "        torch.save(netD_img.state_dict(),\"%s/netD_img_%03d.pth\"%(outf,epoch+1))\n",
    "        torch.save(netD_z.state_dict(),\"%s/netD_z_%03d.pth\"%(outf,epoch+1))\n",
    "\n",
    "\n",
    "    msg1 = \"epoch:{}, step:{}\".format(epoch+1,i+1)\n",
    "    msg2 = format(\"EG_L1_loss:%f\"%(EG_L1_loss.data[0]),\"<30\")+\"|\"+format(\"G_img_loss:%f\"%(G_img_loss.data[0]),\"<30\")\n",
    "    msg5 = format(\"G_tv_loss:%f\"%(G_tv_loss.data[0]),\"<30\")+\"|\"+\"Ez_loss:%f\"%(Ez_loss.data[0])\n",
    "    msg3 = format(\"D_img:%f\"%(D_img.mean().data[0]),\"<30\")+\"|\"+format(\"D_reconst:%f\"%(D_reconst.mean().data[0]),\"<30\")\\\n",
    "    +\"|\"+format(\"D_loss:%f\"%(D_loss.data[0]),\"<30\")\n",
    "    msg4 = format(\"D_z:%f\"%(Dz.mean().data[0]),\"<30\")+\"|\"+format(\"D_z_prior:%f\"%(Dz_prior.mean().data[0]),\"<30\")\\\n",
    "    +\"|\"+format(\"Dz_loss:%f\"%(Dz_loss.data[0]),\"<30\")\n",
    "\n",
    "    print()\n",
    "    print(msg1)\n",
    "    print(msg2)\n",
    "    print(msg5)\n",
    "    print(msg3)\n",
    "    print(msg4)       \n",
    "    print()\n",
    "    print(\"-\"*80)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
